---
title: "Practical Machine Learning Project - Coursera"
author: "Ezeonyebuchi E. C."
date: "21 April 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Introduction:
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health,
to find patterns in their behavior, or because they are tech geeks. One thing that people regularly
do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.

In this project, I will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participant who were asked to perform dumbbell lifts correctly and incorrectly in 5 different ways.
The data consists of a Training data and a Test data (to be used to validate the selected model).
The goal of your project is to predict the manner in which they did the exercise. 
This is the “classe” variable in the training set. You may use any of the other variables to predict with.

```{r}

##Load needed libraries
library(knitr)
library(rattle)
library(randomForest)
library(rpart.plot)
library(caret)
library(rpart)
library(gbm)
library(RColorBrewer)
library(corrplot)


##Downloading the websites
##For the traing data
TrainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
##download.file(TrainURL, destfile = "./pml-training", method="auto")

##For test data
TestUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
##download.file(TestUrl, destfile = "./pml-testing.csv", method = "auto")

##Reading, Cleaning and Exploring the data
trainData <- read.csv("./pml-training", header = TRUE)
head(trainData)
dim(trainData)
str(trainData)
summary(trainData)

testData <- read.csv("./pml-testing.csv", header = TRUE)
head(testData)
dim(testData)
str(testData)
summary(testData)
```
Partioning the training set into two
Partioning Training data set into two data sets.I am using 60% for Training and 40% for myTesting:
```
```{r}
inTrain <- createDataPartition(y = trainData$classe, p=0.6, list=FALSE)
Train <- trainData[inTrain, ]
Test <- trainData[-inTrain, ]
dim(Train)
dim(Test)
```
Cleaning the input data and removing the NAs
```{r}
## Remove missing values (NAs). 
NZVData <- nearZeroVar(Train, saveMetrics=TRUE)
dim(NZVData)
str(NZVData)

NZVvars <- names(Train) %in% c()

Train <- Train[!NZVvars]
#To check the new N?? of observations
dim(Train)

Train <- Train[c(-1)]
##creating another subset to iterate in loop
trainData2 <- Train 
for(i in 1:length(Train)) { 
        if(sum( is.na(Train[, i])) /nrow(Train) >= .6 ) { 
        for(j in 1:length(trainData2)) {
            if(length( grep(names(Train[i]), names(trainData2)[j]) ) ==1)  { 
                trainData2 <- trainData2[ , -j] 
            }   
        } 
    }
}

dim(trainData2)

##Getting back to our set:
Train <- trainData2
rm(trainData2)

```
Do the same for the test set
```{r}
clean1 <- colnames(Train)
clean2 <- colnames(Train[, -58]) 
Test <- Test[clean1]
testData <- testData[clean2]

dim(Test)

dim(testData)
```
Coerce the test data into the same type with the train data to allow proper functioning of RandomForest and other decision trees.
```{r}
for (i in 1:length(testData) ) {
        for(j in 1:length(Train)) {
        if( length( grep(names(Train[i]), names(testData)[j]) ) ==1)  {
            class(testData[j]) <- class(Train[i])
        }      
    }      
}

testData <- rbind(Train[2, -58] , testData) 
testData <- testData[-1,]
```
Using ML algorithms for prediction: Decision Tree
```{r}
modFit <- rpart(classe ~ ., data=Train, method="class")

fancyRpartPlot(modFit)
```
Predicting:
```{r}
predictions <- predict(modFit, Test, type = "class")

confusionMatrix(predictions, Test$classe)
```
Using Random Forests
```{r}
modFitB <- randomForest(classe ~. , data=Train)

predictionsB <- predict(modFitB, Test, type = "class")

confusionMatrix(predictionsB, Test$classe)

```
Random Forests yielded better results.
Generating Files to submit as answers for the Assignment:
```{r}
predictionsB1 <- predict(modFitB, testData, type = "class")

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictionsB)
